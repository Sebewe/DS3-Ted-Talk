{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0aa1577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[K     |████████████████████████████████| 922 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: typing-extensions, catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.5 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.8 typer-0.7.0 typing-extensions-4.5.0 wasabi-1.1.1\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.61.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.19.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2021.10.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e38ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56eddccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('ted_talks_en.csv')\n",
    "#raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6730ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = raw['topics'].to_numpy()\n",
    "keywords = defaultdict(int)\n",
    "for i, inner in enumerate(arr):\n",
    "    x = inner.split(\"'\")\n",
    "    for i, tag in enumerate(x):\n",
    "        if i % 2 != 0 and i != 0 and i != len(x) - 1:\n",
    "            keywords[tag.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b55891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_keywords = sorted(list(keywords.keys()), key=lambda keyword: keywords[keyword])[::-1]\n",
    "occurences = [keywords[keyword] for keyword in most_common_keywords]\n",
    "#list(zip(most_common_keywords, occurences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdbd0e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([380.,  39.,  16.,  10.,   4.,   6.,   1.,   0.,   0.,   2.]),\n",
       " array([  1., 100., 199., 298., 397., 496., 595., 694., 793., 892., 991.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d2955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of topics with occurences >= 80 : 103\n"
     ]
    }
   ],
   "source": [
    "cutoff = 80\n",
    "y = filter(lambda x: x >= cutoff, occurences)\n",
    "print(f\"Amount of topics with occurences >= 80 : {len(list(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60168131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topics(topic):\n",
    "    x = topic.split(\"'\")\n",
    "    tags = []\n",
    "    for i, tag in enumerate(x):\n",
    "        if i % 2 != 0 and i != 0 and i != len(x) - 1:\n",
    "            tags.append(tag.lower())\n",
    "    return tags\n",
    "\n",
    "def correct_dataframe_topics_column(df):\n",
    "    df = df.copy()\n",
    "    topics_listed_column = df['topics'].apply(convert_topics)\n",
    "    df['topics'] = topics_listed_column\n",
    "    return df\n",
    "\n",
    "corrected_topics = correct_dataframe_topics_column(raw)\n",
    "#corrected_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04e8173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topics of focus:\n",
    "STEM - Science, Technology, Engineering, Math(Mathematics), Psychology, Physics, Biotech, AI, Cognitive Science\n",
    "Culture - Culture, Society, Community\n",
    "Business - Business, Economics\n",
    "Social Change - social change/activism\n",
    "History - History/Politics\n",
    "\"\"\"\n",
    "topic_to_group = defaultdict(lambda: 'not-relevant')\n",
    "stem = [\"science\", \"technology\", \"engineering\", \"math\", \"mathematics\", \"psychology\", \"physics\", \"biotech\", \"ai\", \"cognitive science\"]\n",
    "culture = [\"culture\", \"society\", \"community\"]\n",
    "business = [\"business\", \"economics\"]\n",
    "activism = ['social change', 'activism']\n",
    "history = ['history', 'politics']\n",
    "categories = [ ['stem'] + stem, ['culture'] + culture, ['business'] + business,\n",
    "              ['activism'] + activism, ['history'] + history]\n",
    "\n",
    "for category in categories:\n",
    "    cat = None\n",
    "    for i, topic in enumerate(category):\n",
    "        if i == 0:\n",
    "            cat = topic\n",
    "            continue\n",
    "        topic_to_group[topic] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb26c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_topics(topic_list):\n",
    "    grouped = set()\n",
    "    for topic in topic_list:\n",
    "        grouped.add(topic_to_group[topic])\n",
    "    if len(grouped) > 1 and 'not-relevant' in grouped:\n",
    "        grouped.remove('not-relevant')\n",
    "    return grouped\n",
    "\n",
    "def group_df_topics(df):\n",
    "    df = df.copy()\n",
    "    df['topics'] = df['topics'].apply(group_topics)\n",
    "    return df\n",
    "\n",
    "grouped_topics = group_df_topics(corrected_topics)\n",
    "#grouped_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b67ae7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df: pd.DataFrame, verbose=False):\n",
    "    \"\"\"\n",
    "    expects df to have a columns ['words'] which contains a dictionary for each entry,\n",
    "    this dictionary has all the unique words in this row's transcript as keys, and their values\n",
    "    correspond the amount of time that word appears in the transcript. This creates \n",
    "    \"\"\"\n",
    "    word_dicts = df['words'].to_numpy()\n",
    "    total_dict = defaultdict(int)\n",
    "    total_count = 0\n",
    "    for word_dict in word_dicts:\n",
    "        for word in word_dict.keys():\n",
    "            total_dict[word] += word_dict[word]\n",
    "            total_count += word_dict[word]\n",
    "    unique_count = len(list(total_dict.keys()))\n",
    "    if verbose: \n",
    "        print(\"Amount of unique words: {:,}\".format(unique_count), \n",
    "             \"\\nTotal word count: {:,}\".format(total_count))\n",
    "    \n",
    "    word_to_onehot_location = {}\n",
    "    for i, word in list(total_dict.keys()):\n",
    "        word_to_onehot_location[word] = i\n",
    "        \n",
    "    new_col = []\n",
    "    for i, row in enumerate(word_dicts):\n",
    "        new_entry = np.zeros(unique_count, dtype=int)\n",
    "        for word in row:\n",
    "            new_entry[word_to_onehot_location[word]] = 1\n",
    "        new_col.append(new_entry)\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_df['one-hot'] = new_col\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1f55ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank',\n",
       " 'you',\n",
       " 'so',\n",
       " 'much,',\n",
       " 'Chris.',\n",
       " 'And',\n",
       " \"it's\",\n",
       " 'truly',\n",
       " 'a',\n",
       " 'great',\n",
       " 'honor',\n",
       " 'to',\n",
       " 'have',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'come',\n",
       " 'this',\n",
       " 'stage',\n",
       " 'twice;',\n",
       " \"I'm\",\n",
       " 'extremely',\n",
       " 'grateful.',\n",
       " 'I',\n",
       " 'been',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'by',\n",
       " 'conference,',\n",
       " 'and',\n",
       " 'want',\n",
       " 'thank',\n",
       " 'all',\n",
       " 'of',\n",
       " 'for',\n",
       " 'many',\n",
       " 'nice',\n",
       " 'comments',\n",
       " 'about',\n",
       " 'what',\n",
       " 'had',\n",
       " 'say',\n",
       " 'other',\n",
       " 'night.',\n",
       " 'that',\n",
       " 'sincerely,',\n",
       " 'partly',\n",
       " 'because',\n",
       " '(Mock',\n",
       " 'sob)',\n",
       " 'need',\n",
       " 'that.',\n",
       " '(Laughter)',\n",
       " 'Put',\n",
       " 'yourselves',\n",
       " 'in',\n",
       " 'my',\n",
       " 'position.',\n",
       " 'flew',\n",
       " 'on',\n",
       " 'Air',\n",
       " 'Force',\n",
       " 'Two',\n",
       " 'eight',\n",
       " 'years.',\n",
       " 'Now',\n",
       " 'take',\n",
       " 'off',\n",
       " 'shoes',\n",
       " 'or',\n",
       " 'boots',\n",
       " 'get',\n",
       " 'an',\n",
       " 'airplane!',\n",
       " '(Applause)',\n",
       " \"I'll\",\n",
       " 'tell',\n",
       " 'one',\n",
       " 'quick',\n",
       " 'story',\n",
       " 'illustrate',\n",
       " \"that's\",\n",
       " 'like',\n",
       " 'me.',\n",
       " \"It's\",\n",
       " 'true',\n",
       " '—',\n",
       " 'every',\n",
       " 'bit',\n",
       " 'is',\n",
       " 'true.',\n",
       " 'Soon',\n",
       " 'after',\n",
       " 'Tipper',\n",
       " 'left',\n",
       " 'White',\n",
       " 'House',\n",
       " 'we',\n",
       " 'were',\n",
       " 'driving',\n",
       " 'from',\n",
       " 'our',\n",
       " 'home',\n",
       " 'Nashville',\n",
       " 'little',\n",
       " 'farm',\n",
       " '50',\n",
       " 'miles',\n",
       " 'east',\n",
       " 'Nashville.',\n",
       " 'Driving',\n",
       " 'ourselves.',\n",
       " 'know',\n",
       " 'it',\n",
       " 'sounds',\n",
       " 'thing',\n",
       " 'you,',\n",
       " 'but',\n",
       " 'looked',\n",
       " 'rear-view',\n",
       " 'mirror',\n",
       " 'sudden',\n",
       " 'just',\n",
       " 'hit',\n",
       " 'There',\n",
       " 'was',\n",
       " 'no',\n",
       " 'motorcade',\n",
       " 'back',\n",
       " 'there.',\n",
       " \"You've\",\n",
       " 'heard',\n",
       " 'phantom',\n",
       " 'limb',\n",
       " 'pain?',\n",
       " 'This',\n",
       " 'rented',\n",
       " 'Ford',\n",
       " 'Taurus.',\n",
       " 'It',\n",
       " 'dinnertime,',\n",
       " 'started',\n",
       " 'looking',\n",
       " 'place',\n",
       " 'eat.',\n",
       " 'We',\n",
       " 'I-40.',\n",
       " 'got',\n",
       " 'Exit',\n",
       " '238,',\n",
       " 'Lebanon,',\n",
       " 'Tennessee.',\n",
       " 'exit,',\n",
       " 'found',\n",
       " \"Shoney's\",\n",
       " 'restaurant.',\n",
       " 'Low-cost',\n",
       " 'family',\n",
       " 'restaurant',\n",
       " 'chain,',\n",
       " 'those',\n",
       " 'who',\n",
       " \"don't\",\n",
       " 'it.',\n",
       " 'went',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'at',\n",
       " 'booth,',\n",
       " 'waitress',\n",
       " 'came',\n",
       " 'over,',\n",
       " 'made',\n",
       " 'big',\n",
       " 'commotion',\n",
       " 'over',\n",
       " 'Tipper.',\n",
       " 'She',\n",
       " 'took',\n",
       " 'order,',\n",
       " 'then',\n",
       " 'couple',\n",
       " 'booth',\n",
       " 'next',\n",
       " 'us,',\n",
       " 'she',\n",
       " 'lowered',\n",
       " 'her',\n",
       " 'voice',\n",
       " 'really',\n",
       " 'strain',\n",
       " 'hear',\n",
       " 'saying.',\n",
       " 'said',\n",
       " '\"Yes,',\n",
       " 'former',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Al',\n",
       " 'Gore',\n",
       " 'his',\n",
       " 'wife,',\n",
       " 'Tipper.\"',\n",
       " 'man',\n",
       " 'said,',\n",
       " '\"He\\'s',\n",
       " 'long',\n",
       " 'way,',\n",
       " \"hasn't\",\n",
       " 'he?\"',\n",
       " \"There's\",\n",
       " 'kind',\n",
       " 'series',\n",
       " 'epiphanies.',\n",
       " 'The',\n",
       " 'very',\n",
       " 'day,',\n",
       " 'continuing',\n",
       " 'totally',\n",
       " 'story,',\n",
       " 'G-V',\n",
       " 'fly',\n",
       " 'Africa',\n",
       " 'make',\n",
       " 'speech',\n",
       " 'Nigeria,',\n",
       " 'city',\n",
       " 'Lagos,',\n",
       " 'topic',\n",
       " 'energy.',\n",
       " 'began',\n",
       " 'telling',\n",
       " 'them',\n",
       " 'happened',\n",
       " 'day',\n",
       " 'before',\n",
       " 'told',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'same',\n",
       " 'way',\n",
       " \"I've\",\n",
       " 'shared',\n",
       " 'with',\n",
       " 'you:',\n",
       " 'ourselves,',\n",
       " \"Shoney's,\",\n",
       " 'low-cost',\n",
       " 'they',\n",
       " 'laughed.',\n",
       " 'gave',\n",
       " 'speech,',\n",
       " 'out',\n",
       " 'airport',\n",
       " 'home.',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " 'plane',\n",
       " 'until,',\n",
       " 'during',\n",
       " 'middle',\n",
       " 'night,',\n",
       " 'landed',\n",
       " 'Azores',\n",
       " 'Islands',\n",
       " 'refueling.',\n",
       " 'woke',\n",
       " 'up,',\n",
       " 'opened',\n",
       " 'door,',\n",
       " 'some',\n",
       " 'fresh',\n",
       " 'air,',\n",
       " 'looked,',\n",
       " 'there',\n",
       " 'running',\n",
       " 'across',\n",
       " 'runway.',\n",
       " 'he',\n",
       " 'waving',\n",
       " 'piece',\n",
       " 'paper,',\n",
       " 'yelling,',\n",
       " '\"Call',\n",
       " 'Washington!',\n",
       " 'Call',\n",
       " 'Washington!\"',\n",
       " 'thought',\n",
       " 'myself,',\n",
       " 'Atlantic,',\n",
       " 'world',\n",
       " 'could',\n",
       " 'be',\n",
       " 'wrong',\n",
       " 'Washington?',\n",
       " 'Then',\n",
       " 'remembered',\n",
       " 'bunch',\n",
       " 'things.',\n",
       " 'But',\n",
       " 'turned',\n",
       " 'be,',\n",
       " 'staff',\n",
       " 'upset',\n",
       " 'wire',\n",
       " 'services',\n",
       " 'Nigeria',\n",
       " 'already',\n",
       " 'written',\n",
       " 'printed',\n",
       " 'cities',\n",
       " 'United',\n",
       " 'States',\n",
       " 'America.',\n",
       " 'Monterey,',\n",
       " 'checked.',\n",
       " 'began,',\n",
       " '\"Former',\n",
       " 'announced',\n",
       " 'yesterday,\"',\n",
       " 'quote:',\n",
       " \"'My\",\n",
       " 'wife',\n",
       " 'restaurant\\'\"',\n",
       " '\"\\'named',\n",
       " 'are',\n",
       " 'ourselves.\\'\"',\n",
       " 'Before',\n",
       " 'U.S.',\n",
       " 'soil,',\n",
       " 'David',\n",
       " 'Letterman',\n",
       " 'Jay',\n",
       " 'Leno',\n",
       " 'me',\n",
       " 'white',\n",
       " \"chef's\",\n",
       " 'hat,',\n",
       " 'saying,',\n",
       " '\"One',\n",
       " 'more',\n",
       " 'burger',\n",
       " 'fries!\"',\n",
       " 'Three',\n",
       " 'days',\n",
       " 'later,',\n",
       " 'nice,',\n",
       " 'long,',\n",
       " 'handwritten',\n",
       " 'letter',\n",
       " 'friend',\n",
       " 'partner',\n",
       " 'colleague',\n",
       " 'Bill',\n",
       " 'Clinton,',\n",
       " '\"Congratulations',\n",
       " 'new',\n",
       " 'restaurant,',\n",
       " 'Al!\"',\n",
       " 'celebrate',\n",
       " 'each',\n",
       " \"other's\",\n",
       " 'successes',\n",
       " 'life.',\n",
       " 'going',\n",
       " 'talk',\n",
       " 'information',\n",
       " 'ecology.',\n",
       " 'thinking',\n",
       " 'that,',\n",
       " 'since',\n",
       " 'plan',\n",
       " 'lifelong',\n",
       " 'habit',\n",
       " 'coming',\n",
       " 'TED,',\n",
       " 'maybe',\n",
       " 'another',\n",
       " 'time.',\n",
       " 'Chris',\n",
       " 'Anderson:',\n",
       " 'deal!',\n",
       " 'Gore:',\n",
       " 'focus',\n",
       " 'would',\n",
       " 'elaborate',\n",
       " 'on:',\n",
       " 'What',\n",
       " 'can',\n",
       " 'do',\n",
       " 'climate',\n",
       " 'crisis?',\n",
       " 'start',\n",
       " 'show',\n",
       " 'images,',\n",
       " 'recapitulate',\n",
       " 'four',\n",
       " 'five.',\n",
       " 'Now,',\n",
       " 'slide',\n",
       " 'show.',\n",
       " 'update',\n",
       " 'time',\n",
       " 'give',\n",
       " 'add',\n",
       " 'learn',\n",
       " 'beach-combing,',\n",
       " 'know?',\n",
       " 'Every',\n",
       " 'tide',\n",
       " 'comes',\n",
       " 'out,',\n",
       " 'find',\n",
       " 'shells.',\n",
       " 'Just',\n",
       " 'last',\n",
       " 'two',\n",
       " 'days,',\n",
       " 'temperature',\n",
       " 'records',\n",
       " 'January.',\n",
       " 'Historical',\n",
       " 'average',\n",
       " 'Januarys',\n",
       " '31',\n",
       " 'degrees;',\n",
       " 'month',\n",
       " '39.5',\n",
       " 'degrees.',\n",
       " 'wanted',\n",
       " 'bad',\n",
       " 'news',\n",
       " 'environment',\n",
       " 'kidding.',\n",
       " 'these',\n",
       " 'recapitulation',\n",
       " 'slides,',\n",
       " 'go',\n",
       " 'into',\n",
       " 'material',\n",
       " 'do.',\n",
       " 'these.',\n",
       " 'First',\n",
       " 'all,',\n",
       " 'where',\n",
       " \"we're\",\n",
       " 'projected',\n",
       " 'contribution',\n",
       " 'global',\n",
       " 'warming,',\n",
       " 'under',\n",
       " 'business',\n",
       " 'as',\n",
       " 'usual.',\n",
       " 'Efficiency',\n",
       " 'end-use',\n",
       " 'electricity',\n",
       " 'energy',\n",
       " 'low-hanging',\n",
       " 'fruit.',\n",
       " 'conservation',\n",
       " 'not',\n",
       " 'cost;',\n",
       " 'profit.',\n",
       " 'sign',\n",
       " 'wrong.',\n",
       " 'negative;',\n",
       " 'positive.',\n",
       " 'These',\n",
       " 'investments',\n",
       " 'pay',\n",
       " 'themselves.',\n",
       " 'also',\n",
       " 'effective',\n",
       " 'deflecting',\n",
       " 'path.',\n",
       " 'Cars',\n",
       " 'trucks',\n",
       " 'talked',\n",
       " 'slideshow,',\n",
       " 'put',\n",
       " 'perspective.',\n",
       " 'easy,',\n",
       " 'visible',\n",
       " 'target',\n",
       " 'concern',\n",
       " 'should',\n",
       " 'warming',\n",
       " 'pollution',\n",
       " 'buildings',\n",
       " 'than',\n",
       " 'cars',\n",
       " 'trucks.',\n",
       " 'significant,',\n",
       " 'lowest',\n",
       " 'standards',\n",
       " 'world.',\n",
       " 'address',\n",
       " 'part',\n",
       " 'puzzle.',\n",
       " 'Other',\n",
       " 'transportation',\n",
       " 'efficiency',\n",
       " 'important',\n",
       " 'Renewables',\n",
       " 'current',\n",
       " 'levels',\n",
       " 'technological',\n",
       " 'difference.',\n",
       " 'Vinod,',\n",
       " 'John',\n",
       " 'Doerr',\n",
       " 'others,',\n",
       " 'here',\n",
       " 'lot',\n",
       " 'people',\n",
       " 'directly',\n",
       " 'involved',\n",
       " 'wedge',\n",
       " 'grow',\n",
       " 'rapidly',\n",
       " 'projection',\n",
       " 'shows',\n",
       " 'Carbon',\n",
       " 'Capture',\n",
       " 'Sequestration',\n",
       " 'CCS',\n",
       " 'stands',\n",
       " 'likely',\n",
       " 'become',\n",
       " 'killer',\n",
       " 'app',\n",
       " 'will',\n",
       " 'enable',\n",
       " 'us',\n",
       " 'continue',\n",
       " 'use',\n",
       " 'fossil',\n",
       " 'fuels',\n",
       " 'safe.',\n",
       " 'Not',\n",
       " 'quite',\n",
       " 'yet.',\n",
       " 'OK.',\n",
       " 'do?',\n",
       " 'Reduce',\n",
       " 'emissions',\n",
       " 'your',\n",
       " 'Most',\n",
       " 'expenditures',\n",
       " 'profitable.',\n",
       " 'Insulation,',\n",
       " 'better',\n",
       " 'design.',\n",
       " 'Buy',\n",
       " 'green',\n",
       " 'can.',\n",
       " 'mentioned',\n",
       " 'automobiles',\n",
       " 'buy',\n",
       " 'hybrid.',\n",
       " 'Use',\n",
       " 'light',\n",
       " 'rail.',\n",
       " 'Figure',\n",
       " 'options',\n",
       " 'better.',\n",
       " 'important.',\n",
       " 'Be',\n",
       " 'consumer.',\n",
       " 'You',\n",
       " 'choices',\n",
       " 'everything',\n",
       " 'buy,',\n",
       " 'between',\n",
       " 'things',\n",
       " 'harsh',\n",
       " 'effect,',\n",
       " 'less',\n",
       " 'effect',\n",
       " 'crisis.',\n",
       " 'Consider',\n",
       " 'this:',\n",
       " 'Make',\n",
       " 'decision',\n",
       " 'live',\n",
       " 'carbon-neutral',\n",
       " 'Those',\n",
       " 'good',\n",
       " 'branding,',\n",
       " \"I'd\",\n",
       " 'love',\n",
       " 'advice',\n",
       " 'help',\n",
       " 'how',\n",
       " 'connects',\n",
       " 'most',\n",
       " 'people.',\n",
       " 'easier',\n",
       " 'think.',\n",
       " 'is.',\n",
       " 'A',\n",
       " 'decision,',\n",
       " 'easy.',\n",
       " 'means',\n",
       " 'reduce',\n",
       " 'carbon',\n",
       " 'dioxide',\n",
       " 'full',\n",
       " 'range',\n",
       " 'make,',\n",
       " 'purchase',\n",
       " 'acquire',\n",
       " 'offsets',\n",
       " 'remainder',\n",
       " 'completely',\n",
       " 'reduced.',\n",
       " 'elaborated',\n",
       " 'climatecrisis.net.',\n",
       " 'calculator.',\n",
       " 'Participant',\n",
       " 'Productions',\n",
       " 'convened',\n",
       " 'active',\n",
       " 'involvement',\n",
       " 'leading',\n",
       " 'software',\n",
       " 'writers',\n",
       " 'world,',\n",
       " 'arcane',\n",
       " 'science',\n",
       " 'calculation,',\n",
       " 'construct',\n",
       " 'consumer-friendly',\n",
       " 'precisely',\n",
       " 'calculate',\n",
       " 'CO2',\n",
       " 'are,',\n",
       " 'given',\n",
       " 'reduce.',\n",
       " 'movie',\n",
       " 'May,',\n",
       " 'updated',\n",
       " '2.0,',\n",
       " 'click-through',\n",
       " 'purchases',\n",
       " 'offsets.',\n",
       " 'Next,',\n",
       " 'consider',\n",
       " 'making',\n",
       " 'carbon-neutral.',\n",
       " 'Again,',\n",
       " 'done',\n",
       " 'hard',\n",
       " 'Integrate',\n",
       " 'solutions',\n",
       " 'innovations,',\n",
       " 'whether',\n",
       " 'technology,',\n",
       " 'entertainment,',\n",
       " 'design',\n",
       " 'architecture',\n",
       " 'community.',\n",
       " 'Invest',\n",
       " 'sustainably.',\n",
       " 'Majora',\n",
       " 'this.',\n",
       " 'Listen,',\n",
       " 'if',\n",
       " 'invested',\n",
       " 'money',\n",
       " 'managers',\n",
       " 'compensate',\n",
       " 'basis',\n",
       " 'their',\n",
       " 'annual',\n",
       " 'performance,',\n",
       " 'ever',\n",
       " 'again',\n",
       " 'complain',\n",
       " 'quarterly',\n",
       " 'report',\n",
       " 'CEO',\n",
       " 'management.',\n",
       " 'Over',\n",
       " 'time,',\n",
       " 'judge',\n",
       " \"they're\",\n",
       " 'paid',\n",
       " 'capital',\n",
       " \"they've\",\n",
       " 'invested,',\n",
       " 'based',\n",
       " 'short-term',\n",
       " 'returns,',\n",
       " \"you're\",\n",
       " 'decisions.',\n",
       " 'Become',\n",
       " 'catalyst',\n",
       " 'change.',\n",
       " 'Teach',\n",
       " 'it,',\n",
       " 'version',\n",
       " 'slideshow',\n",
       " 'nights',\n",
       " 'ago,',\n",
       " 'except',\n",
       " 'entertaining.',\n",
       " 'May.',\n",
       " 'Many',\n",
       " 'ensure',\n",
       " 'see',\n",
       " 'sending',\n",
       " 'somebody',\n",
       " 'Pick',\n",
       " 'well.',\n",
       " 'am',\n",
       " 'personally',\n",
       " 'train',\n",
       " 're-purposed,',\n",
       " 'personal',\n",
       " 'stories',\n",
       " 'obviously',\n",
       " 'replaced',\n",
       " 'generic',\n",
       " 'approach,',\n",
       " 'mean.',\n",
       " 'link',\n",
       " 'together.',\n",
       " 'conducting',\n",
       " 'course',\n",
       " 'summer',\n",
       " 'group',\n",
       " 'nominated',\n",
       " 'different',\n",
       " 'folks',\n",
       " 'en',\n",
       " 'masse,',\n",
       " 'communities',\n",
       " 'country,',\n",
       " 'single',\n",
       " 'week,',\n",
       " 'keep',\n",
       " 'right',\n",
       " 'cutting',\n",
       " 'edge.',\n",
       " 'Working',\n",
       " 'Larry',\n",
       " 'Lessig,',\n",
       " 'somewhere',\n",
       " 'process,',\n",
       " 'posted',\n",
       " 'tools',\n",
       " 'limited-use',\n",
       " 'copyrights,',\n",
       " 'young',\n",
       " 'remix',\n",
       " 'own',\n",
       " 'way.',\n",
       " 'Where',\n",
       " 'did',\n",
       " 'anybody',\n",
       " 'idea',\n",
       " 'ought',\n",
       " 'stay',\n",
       " \"arm's\",\n",
       " 'length',\n",
       " 'politics?',\n",
       " \"doesn't\",\n",
       " 'mean',\n",
       " 'Republican,',\n",
       " 'trying',\n",
       " 'convince',\n",
       " 'Democrat.',\n",
       " 'Republicans',\n",
       " 'used',\n",
       " 'bipartisan',\n",
       " 'issue,',\n",
       " 'politically',\n",
       " 'active.',\n",
       " 'democracy',\n",
       " 'work',\n",
       " 'supposed',\n",
       " 'work.',\n",
       " 'Support',\n",
       " 'capping',\n",
       " 'trading',\n",
       " \"Here's\",\n",
       " 'why:',\n",
       " 'system,',\n",
       " 'closed',\n",
       " 'system.',\n",
       " 'Once',\n",
       " 'becomes',\n",
       " 'participation,',\n",
       " 'everybody',\n",
       " \"who's\",\n",
       " 'board',\n",
       " 'directors',\n",
       " 'serve',\n",
       " 'corporation?',\n",
       " 'legal',\n",
       " 'liability',\n",
       " 'urge',\n",
       " 'maximum',\n",
       " 'income',\n",
       " 'reducing',\n",
       " 'avoided.',\n",
       " 'market',\n",
       " 'solve',\n",
       " 'problem',\n",
       " 'accomplish',\n",
       " 'Help',\n",
       " 'mass',\n",
       " 'persuasion',\n",
       " 'campaign',\n",
       " 'spring.',\n",
       " 'change',\n",
       " 'minds',\n",
       " 'American',\n",
       " 'Because',\n",
       " 'presently,',\n",
       " 'politicians',\n",
       " 'permission',\n",
       " 'needs',\n",
       " 'done.',\n",
       " 'modern',\n",
       " 'role',\n",
       " 'logic',\n",
       " 'reason',\n",
       " 'longer',\n",
       " 'includes',\n",
       " 'mediating',\n",
       " 'wealth',\n",
       " 'power',\n",
       " 'once',\n",
       " 'did.',\n",
       " 'now',\n",
       " 'repetition',\n",
       " 'short,',\n",
       " 'hot-button,',\n",
       " '30-second,',\n",
       " '28-second',\n",
       " 'television',\n",
       " 'ads.',\n",
       " \"Let's\",\n",
       " 're-brand',\n",
       " 'suggested.',\n",
       " '\"climate',\n",
       " 'crisis\"',\n",
       " 'instead',\n",
       " 'collapse,\"',\n",
       " 'again,',\n",
       " 'Somebody',\n",
       " 'test',\n",
       " 'facing',\n",
       " 'now,',\n",
       " 'scientist',\n",
       " 'me,',\n",
       " 'combination',\n",
       " 'opposable',\n",
       " 'thumb',\n",
       " 'neocortex',\n",
       " 'viable',\n",
       " 'combination.',\n",
       " \"That's\",\n",
       " 'repeat',\n",
       " 'now:',\n",
       " 'political',\n",
       " 'issue.',\n",
       " \"shouldn't\",\n",
       " 'partisan.',\n",
       " 'influence',\n",
       " 'Democrats',\n",
       " 'opportunity.',\n",
       " 'this,',\n",
       " 'connected',\n",
       " 'ideas',\n",
       " 'here,',\n",
       " 'bring',\n",
       " 'coherence',\n",
       " 'them.',\n",
       " 'one.',\n",
       " 'appreciate',\n",
       " 'About',\n",
       " '10',\n",
       " 'years',\n",
       " 'task',\n",
       " 'teach',\n",
       " 'development',\n",
       " 'Swedish',\n",
       " 'undergraduate',\n",
       " 'students.',\n",
       " 'That',\n",
       " 'having',\n",
       " 'spent',\n",
       " '20',\n",
       " 'years,',\n",
       " 'together',\n",
       " 'African',\n",
       " 'institutions,',\n",
       " 'studying',\n",
       " 'hunger',\n",
       " 'Africa.',\n",
       " 'So',\n",
       " 'sort',\n",
       " 'expected',\n",
       " 'started,',\n",
       " 'medical',\n",
       " 'university,',\n",
       " 'Karolinska',\n",
       " 'Institute,',\n",
       " 'called',\n",
       " 'Global',\n",
       " 'Health.',\n",
       " 'when',\n",
       " 'opportunity,',\n",
       " 'nervous.',\n",
       " 'thought,',\n",
       " 'students',\n",
       " 'actually',\n",
       " 'highest',\n",
       " 'grade',\n",
       " 'college',\n",
       " 'about.',\n",
       " 'pretest',\n",
       " 'came.',\n",
       " 'questions',\n",
       " 'which',\n",
       " 'learned',\n",
       " 'one:',\n",
       " '\"Which',\n",
       " 'country',\n",
       " 'has',\n",
       " 'child',\n",
       " 'mortality',\n",
       " 'five',\n",
       " 'pairs?\"',\n",
       " 'pair',\n",
       " 'countries,',\n",
       " 'twice',\n",
       " 'other.',\n",
       " 'bigger,',\n",
       " 'difference,',\n",
       " 'uncertainty',\n",
       " 'data.',\n",
       " \"won't\",\n",
       " 'Turkey,',\n",
       " 'there,',\n",
       " 'Poland,',\n",
       " 'Russia,',\n",
       " 'Pakistan',\n",
       " 'South',\n",
       " 'results',\n",
       " 'confidence',\n",
       " 'interval,',\n",
       " 'narrow.',\n",
       " 'happy,',\n",
       " '1.8',\n",
       " 'answer',\n",
       " 'possible.',\n",
       " 'professor',\n",
       " 'international',\n",
       " 'health',\n",
       " 'course.',\n",
       " 'late',\n",
       " 'compiling',\n",
       " 'report,',\n",
       " 'realized',\n",
       " 'discovery.',\n",
       " 'shown',\n",
       " 'top',\n",
       " 'know,',\n",
       " 'statistically,',\n",
       " 'significantly',\n",
       " 'chimpanzees.',\n",
       " 'chimpanzee',\n",
       " 'score',\n",
       " 'half',\n",
       " 'bananas',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'Turkey.',\n",
       " 'They',\n",
       " 'cases.',\n",
       " 'ignorance;',\n",
       " 'preconceived',\n",
       " 'ideas.',\n",
       " 'unethical',\n",
       " 'study',\n",
       " 'professors',\n",
       " 'hands',\n",
       " 'Nobel',\n",
       " 'Prize',\n",
       " 'Medicine,',\n",
       " 'par',\n",
       " 'communicate,',\n",
       " 'data',\n",
       " \"what's\",\n",
       " 'happening',\n",
       " 'well',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3581f2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcedf'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abc...edf'\n",
    "x.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a93c8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.copy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb85e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f13fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(grouped_topics.iloc[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5059fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4706371 ,  0.21765131, -1.0314393 , ...,  1.4120553 ,\n",
       "        -0.944253  ,  0.50613815],\n",
       "       [-0.16434939,  0.82951665, -0.6400423 , ..., -0.08375989,\n",
       "        -0.1077116 , -0.34314856],\n",
       "       [ 1.3233514 , -0.01322406,  0.2967692 , ...,  1.2514224 ,\n",
       "        -1.7730263 , -0.17876387],\n",
       "       ...,\n",
       "       [-0.20854652, -1.1892142 , -0.16210335, ..., -0.37219468,\n",
       "        -0.31842452,  0.71036816],\n",
       "       [-0.76609504, -0.22358406, -1.0391988 , ..., -0.0962096 ,\n",
       "         1.8497169 ,  1.5730871 ],\n",
       "       [-1.1381158 , -0.25188053, -0.5198487 , ..., -0.23793721,\n",
       "         0.19479394, -1.4996935 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fdda8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `str.remove` not found.\n"
     ]
    }
   ],
   "source": [
    "str.remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76576521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
