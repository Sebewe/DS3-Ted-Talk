{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0aa1577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.10.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.61.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.19.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e38ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import re\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56eddccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('ted_talks_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6730ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = raw['topics'].to_numpy()\n",
    "keywords = defaultdict(int)\n",
    "for i, inner in enumerate(arr):\n",
    "    x = inner.split(\"'\")\n",
    "    for i, tag in enumerate(x):\n",
    "        if i % 2 != 0 and i != 0 and i != len(x) - 1:\n",
    "            keywords[tag.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b55891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_keywords = sorted(list(keywords.keys()), key=lambda keyword: keywords[keyword])[::-1]\n",
    "occurences = [keywords[keyword] for keyword in most_common_keywords]\n",
    "#list(zip(most_common_keywords, occurences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdbd0e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([176., 103.,  45.,  31.,  25.,  10.,  10.,  10.,   7.,   3.,   5.,\n",
       "          6.,   2.,   2.,   1.,   1.,   3.,   2.,   1.,   2.,   1.,   0.,\n",
       "          2.,   0.,   1.,   2.,   0.,   1.,   2.,   1.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1.]),\n",
       " array([  0,  20,  40,  60,  80, 100, 120, 140, 160, 180, 200, 220, 240,\n",
       "        260, 280, 300, 320, 340, 360, 380, 400, 420, 440, 460, 480, 500,\n",
       "        520, 540, 560, 580, 600, 620, 640, 660, 680, 700, 720, 740, 760,\n",
       "        780, 800, 820, 840, 860, 880, 900, 920, 940, 960, 980]),\n",
       " <BarContainer object of 49 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(occurences, bins=np.arange(0, 1000, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d2955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of topics with occurences >= 80 : 103\n"
     ]
    }
   ],
   "source": [
    "cutoff = 80\n",
    "y = filter(lambda x: x >= cutoff, occurences)\n",
    "print(f\"Amount of topics with occurences >= 80 : {len(list(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60168131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topics(topic):\n",
    "    x = topic.split(\"'\")\n",
    "    tags = []\n",
    "    for i, tag in enumerate(x):\n",
    "        if i % 2 != 0 and i != 0 and i != len(x) - 1:\n",
    "            tags.append(tag.lower())\n",
    "    return tags\n",
    "\n",
    "def correct_dataframe_topics_column(df, in_place=False):\n",
    "    if not in_place:\n",
    "        df = df.copy()\n",
    "    topics_listed_column = df['topics'].apply(convert_topics)\n",
    "    df['topics'] = topics_listed_column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e8173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topics of focus:\n",
    "STEM - Science, Technology, Engineering, Math(Mathematics), Psychology, Physics, Biotech, AI, Cognitive Science\n",
    "Culture - Culture, Society, Community\n",
    "Business - Business, Economics\n",
    "Social Change - social change/activism\n",
    "History - History/Politics\n",
    "\"\"\"\n",
    "topic_to_group = defaultdict(lambda: 'not-relevant')\n",
    "stem = [\"science\", \"technology\", \"engineering\", \"math\", \"mathematics\", \"psychology\", \"physics\", \"biotech\", \"ai\", \"cognitive science\"]\n",
    "culture = [\"culture\", \"society\", \"community\"]\n",
    "business = [\"business\", \"economics\"]\n",
    "activism = ['social change', 'activism']\n",
    "history = ['history', 'politics']\n",
    "categories = [ ['stem'] + stem, ['culture'] + culture, ['business'] + business,\n",
    "              ['activism'] + activism, ['history'] + history]\n",
    "\n",
    "for category in categories:\n",
    "    cat = None\n",
    "    for i, topic in enumerate(category):\n",
    "        if i == 0:\n",
    "            cat = topic\n",
    "            continue\n",
    "        topic_to_group[topic] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb26c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_topics(topic_list):\n",
    "    grouped = set()\n",
    "    for topic in topic_list:\n",
    "        grouped.add(topic_to_group[topic])\n",
    "    if len(grouped) > 1 and 'not-relevant' in grouped:\n",
    "        grouped.remove('not-relevant')\n",
    "    return grouped\n",
    "\n",
    "def group_df_topics(df, in_place=False):\n",
    "    if not in_place:\n",
    "        df = df.copy()\n",
    "    df['grouped_topics'] = df['topics'].apply(group_topics)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1b0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_words(script): \n",
    "    unique_words = dict()\n",
    "    script_lst = script.split()\n",
    "    for word in script_lst: \n",
    "        if word in unique_words: \n",
    "            unique_words[word] += 1\n",
    "        else: \n",
    "            unique_words[word] = 1\n",
    "    return unique_words\n",
    "\n",
    "def add_words(df, in_place=False):\n",
    "    if in_place:\n",
    "        df = df.copy()\n",
    "    df[\"clean_scripts\"] = (\n",
    "    df[\"transcript\"]\n",
    "    .str.replace(r'\\(Music: [^)]+\\) ','', regex = True)\n",
    "    .str.replace(r' — ', ' ', regex = True)\n",
    "    .str.replace(r'[[.\"\\'!\\],:?;=+*&]', '', regex = True)\n",
    "    .str.lower())\n",
    "    df[\"words\"] = df[\"clean_scripts\"].apply(count_unique_words)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67ae7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df: pd.DataFrame, verbose=False, in_place=False):\n",
    "    \"\"\"\n",
    "    expects df to have a columns ['words'] which contains a dictionary for each entry,\n",
    "    this dictionary has all the unique words in this row's transcript as keys, and their values\n",
    "    correspond the amount of time that word appears in the transcript. This creates \n",
    "    \"\"\"\n",
    "    word_dicts = df['words'].to_numpy()\n",
    "    total_dict = defaultdict(int)\n",
    "    total_count = 0\n",
    "    for word_dict in word_dicts:\n",
    "        for word in word_dict.keys():\n",
    "            total_dict[word] += word_dict[word]\n",
    "            total_count += word_dict[word]\n",
    "    unique_count = len(list(total_dict.keys()))\n",
    "    if verbose: \n",
    "        print(\"Amount of unique words: {:,}\".format(unique_count), \n",
    "             \"\\nTotal word count: {:,}\".format(total_count))\n",
    "    \n",
    "    word_to_onehot_location = {}\n",
    "    for i, word in enumerate(list(total_dict.keys())):\n",
    "        word_to_onehot_location[word] = i\n",
    "        \n",
    "    new_col = []\n",
    "    for i, row in enumerate(word_dicts):\n",
    "        new_entry = np.zeros(unique_count, dtype=int)\n",
    "        for word in row:\n",
    "            new_entry[word_to_onehot_location[word]] = 1\n",
    "        new_col.append(new_entry)\n",
    "    if in_place:\n",
    "        new_df = df\n",
    "    else:\n",
    "        new_df = df.copy()\n",
    "    new_df['one-hot'] = new_col\n",
    "    return new_df\n",
    "\n",
    "def sentence_type(df, in_place=False):\n",
    "    \"\"\"\n",
    "    adds an array to each row\n",
    "    this array contains the frequency of each setence type\n",
    "    arr[0] = . | arr[1] = ? | arr[2] = !\n",
    "    each entry is total occurences / total punctuation count\n",
    "    \"\"\"\n",
    "    new_col = []\n",
    "    for transcript in df['transcript']:\n",
    "        new_entry = np.zeros(3)\n",
    "        p_count, q_count, e_count = transcript.count('.'), transcript.count('?'), transcript.count('!')\n",
    "        total_sentences = p_count + q_count + e_count + 1\n",
    "        new_entry[0] = (p_count + 1)/ total_sentences\n",
    "        new_entry[1] = (q_count + 1)/ total_sentences\n",
    "        new_entry[2] = (e_count + 1)/ total_sentences\n",
    "        new_col.append(new_entry)\n",
    "    if in_place:\n",
    "        new_df = df\n",
    "    else:\n",
    "        new_df = df.copy()\n",
    "    new_df['sentence-type'] = new_col\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3263e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF Calculation\n",
    "def tfidf_value(transcript):\n",
    "    tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "    tfIdf = tfIdfVectorizer.fit_transform([transcript])\n",
    "    #list_of_words_tfidf = tfIdfVectorizer.get_feature_names_out()\n",
    "    tfidf_value = tfIdf.toarray()[0]\n",
    "    return tfidf_value\n",
    "\n",
    "def tfidf_words(transcript):\n",
    "    tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "    tfIdf = tfIdfVectorizer.fit_transform([transcript])\n",
    "    try:\n",
    "        list_of_words_tfidf = tfIdfVectorizer.get_feature_names_out()\n",
    "    except Error:\n",
    "        list_of_words_tfidf = tfIdfVectorizer.get_feature_names()\n",
    "    tfidf_words = list_of_words_tfidf\n",
    "    return tfidf_words\n",
    "\n",
    "def tfidf_dict(transcript):\n",
    "    tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "    tfIdf = tfIdfVectorizer.fit_transform([transcript])\n",
    "    try:\n",
    "        list_of_words_tfidf = tfIdfVectorizer.get_feature_names_out()\n",
    "    except Error:\n",
    "        list_of_words_tfidf = tfIdfVectorizer.get_feature_names()\n",
    "    tfidf_value = tfIdf.toarray()[0]\n",
    "    tfidf_dict = dict(zip(list_of_words_tfidf,tfidf_value))\n",
    "    return tfidf_dict\n",
    "\n",
    "def add_tfidf(df: pd.DataFrame, in_place=False):\n",
    "    if in_place:\n",
    "        df = df.copy()\n",
    "    df['tfidf'] = df['transcript'].apply(tfidf_value)\n",
    "    df['tfidf_word'] = df['transcript'].apply(tfidf_words)\n",
    "    df['tfidf_dict'] = df['transcript'].apply(tfidf_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8491b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_engineered():\n",
    "    data = raw.copy()\n",
    "    data = correct_dataframe_topics_column(data, in_place=True)\n",
    "    data = group_df_topics(data, in_place=True)\n",
    "    data = add_words(data, in_place=True)\n",
    "    data = one_hot_encode(data, in_place=True)\n",
    "    data = sentence_type(data, in_place=True)\n",
    "    data = add_tfidf(data, in_place=True)\n",
    "    data = data.drop(columns = [\n",
    "    \"talk_id\", \"speaker_1\", \"views\", \"recorded_date\", \"published_date\", \n",
    "    \"event\", \"duration\", \"url\", \"comments\", \"about_speakers\", \n",
    "    \"available_lang\", \"all_speakers\", \"native_lang\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83abe3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_feature_engineered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b73a432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>occupations</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "      <th>grouped_topics</th>\n",
       "      <th>clean_scripts</th>\n",
       "      <th>words</th>\n",
       "      <th>one-hot</th>\n",
       "      <th>sentence-type</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>tfidf_word</th>\n",
       "      <th>tfidf_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[alternative energy, cars, climate change, cul...</td>\n",
       "      <td>{243: 'New thinking on the climate crisis', 54...</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>{culture, stem}</td>\n",
       "      <td>thank you so much chris and its truly a great ...</td>\n",
       "      <td>{'thank': 3, 'you': 39, 'so': 5, 'much': 9, 'c...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.9096774193548387, 0.05806451612903226, 0.04...</td>\n",
       "      <td>[0.004944137818219958, 0.004944137818219958, 0...</td>\n",
       "      <td>[238, 28, 30, 31, 39, 40, 50, about, accomplis...</td>\n",
       "      <td>{'238': 0.004944137818219958, '28': 0.00494413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>{0: ['global health expert; data visionary']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[africa, asia, google, demo, economics, global...</td>\n",
       "      <td>{2056: \"Own your body's data\", 2296: 'A visual...</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>{business, stem}</td>\n",
       "      <td>about 10 years ago i took on the task to teach...</td>\n",
       "      <td>{'about': 15, '10': 3, 'years': 9, 'ago': 1, '...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.9116465863453815, 0.09236947791164658, 0.00...</td>\n",
       "      <td>[0.0029276458487846966, 0.00878293754635409, 0...</td>\n",
       "      <td>[000, 10, 100, 1960, 1962, 1964, 1970, 1974, 2...</td>\n",
       "      <td>{'000': 0.0029276458487846966, '10': 0.0087829...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[computers, entertainment, interface design, m...</td>\n",
       "      <td>{1725: '10 top time-saving tech tips', 2274: '...</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>{stem}</td>\n",
       "      <td>hello voice mail my old friend (laughter) ive ...</td>\n",
       "      <td>{'hello': 1, 'voice': 3, 'mail': 2, 'my': 17, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.8561872909698997, 0.12040133779264214, 0.03...</td>\n",
       "      <td>[0.003229757844257144, 0.003229757844257144, 0...</td>\n",
       "      <td>[000, 10, 11, 12, 18, 1982, 1997, 20, 200, 200...</td>\n",
       "      <td>{'000': 0.003229757844257144, '10': 0.00322975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>{0: ['activist for environmental justice']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[macarthur grant, activism, business, cities, ...</td>\n",
       "      <td>{1041: '3 stories of local eco-entrepreneurshi...</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>{business, activism, history}</td>\n",
       "      <td>if youre here today and im very happy that you...</td>\n",
       "      <td>{'if': 6, 'youre': 3, 'here': 6, 'today': 3, '...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.9187817258883249, 0.06598984771573604, 0.02...</td>\n",
       "      <td>[0.015522192347839546, 0.007761096173919773, 0...</td>\n",
       "      <td>[000, 10, 1960s, 1990s, 1998, 20, 25, 27, 28, ...</td>\n",
       "      <td>{'000': 0.015522192347839546, '10': 0.00776109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>{0: ['author', 'educator']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[children, creativity, culture, dance, educati...</td>\n",
       "      <td>{865: 'Bring on the learning revolution!', 173...</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>Good morning. How are you? (Audience) Good. It...</td>\n",
       "      <td>{culture}</td>\n",
       "      <td>good morning how are you (audience) good its b...</td>\n",
       "      <td>{'good': 4, 'morning': 1, 'how': 7, 'are': 19,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.8489208633093526, 0.14388489208633093, 0.01...</td>\n",
       "      <td>[0.0033326113457486047, 0.0066652226914972095,...</td>\n",
       "      <td>[15, 16, 1930s, 19th, 20, 2065, 21, 30, 30s, 5...</td>\n",
       "      <td>{'15': 0.0033326113457486047, '16': 0.00666522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>Crisis support for the world, one text away</td>\n",
       "      <td>{0: ['health activist']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[activism, data, technology, mental health, so...</td>\n",
       "      <td>{2362: 'How data from a crisis text line is sa...</td>\n",
       "      <td>What if we could help people in crisis anytime...</td>\n",
       "      <td>\"I'm 14, and I want to go home.\" \"My name is B...</td>\n",
       "      <td>{culture, activism, stem}</td>\n",
       "      <td>im 14 and i want to go home my name is beth im...</td>\n",
       "      <td>{'im': 3, '14': 1, 'and': 76, 'i': 14, 'want':...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.9632352941176471, 0.04411764705882353, 0.00...</td>\n",
       "      <td>[0.017823075144987977, 0.005941025048329325, 0...</td>\n",
       "      <td>[000, 12, 14, 150, 17, 19, 20, 2013, 24, 26, 2...</td>\n",
       "      <td>{'000': 0.017823075144987977, '12': 0.00594102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>The dark history of IQ tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[ted-ed, education, history, animation, intell...</td>\n",
       "      <td>{35386: 'How does the Rorschach inkblot test w...</td>\n",
       "      <td>In 1905, psychologists Alfred Binet and Théodo...</td>\n",
       "      <td>In 1905, psychologists Alfred Binet and Théodo...</td>\n",
       "      <td>{stem, history}</td>\n",
       "      <td>in 1905 psychologists alfred binet and théodor...</td>\n",
       "      <td>{'in': 17, '1905': 1, 'psychologists': 3, 'alf...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1.0, 0.02857142857142857, 0.02857142857142857]</td>\n",
       "      <td>[0.03855034965325704, 0.01285011655108568, 0.0...</td>\n",
       "      <td>[100, 15, 1905, 1924, 19th, 20th, 68, abilitie...</td>\n",
       "      <td>{'100': 0.03855034965325704, '15': 0.012850116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>How \"policing for profit\" undermines your rights</td>\n",
       "      <td>{0: ['law researcher']}</td>\n",
       "      <td>en</td>\n",
       "      <td>[society, law, policy, justice system, tedx]</td>\n",
       "      <td>{2406: 'I love being a police officer, but we ...</td>\n",
       "      <td>Many countries have an active, centuries-old l...</td>\n",
       "      <td>Picture yourself driving down the road tomorro...</td>\n",
       "      <td>{culture}</td>\n",
       "      <td>picture yourself driving down the road tomorro...</td>\n",
       "      <td>{'picture': 1, 'yourself': 1, 'driving': 1, 'd...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.944954128440367, 0.06422018348623854, 0.009...</td>\n",
       "      <td>[0.02596745720022887, 0.006491864300057218, 0....</td>\n",
       "      <td>[000, 1955, 1980s, 1990, 1997, 200, 2001, 2002...</td>\n",
       "      <td>{'000': 0.02596745720022887, '1955': 0.0064918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>The electrifying speeches of Sojourner Truth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[ted-ed, education, animation, united states, ...</td>\n",
       "      <td>{20973: 'The breathtaking courage of Harriet T...</td>\n",
       "      <td>Isabella Baumfree was born into slavery in lat...</td>\n",
       "      <td>In early 1828, Sojourner Truth approached the ...</td>\n",
       "      <td>{activism, history}</td>\n",
       "      <td>in early 1828 sojourner truth approached the g...</td>\n",
       "      <td>{'in': 20, 'early': 1, '1828': 2, 'sojourner':...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0.95, 0.025, 0.075]</td>\n",
       "      <td>[0.01362089413207989, 0.01362089413207989, 0.0...</td>\n",
       "      <td>[1799, 1826, 1828, 1843, 1883, 18th, 20s, 80s,...</td>\n",
       "      <td>{'1799': 0.01362089413207989, '1826': 0.013620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>The most important anus in the ocean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[animals, ted-ed, animation, oceans, science, ...</td>\n",
       "      <td>{62347: 'The bug that poops candy', 29159: 'In...</td>\n",
       "      <td>Is it a fuzzy sock? An overripe banana? A mold...</td>\n",
       "      <td>Can you guess what you’re looking at? Is it a ...</td>\n",
       "      <td>{stem}</td>\n",
       "      <td>can you guess what you’re looking at is it a f...</td>\n",
       "      <td>{'can': 5, 'you': 1, 'guess': 1, 'what': 2, 'y...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.8888888888888888, 0.1388888888888889, 0.027...</td>\n",
       "      <td>[0.016373653066597823, 0.016373653066597823, 0...</td>\n",
       "      <td>[000, 95, able, about, abyssal, acidification,...</td>\n",
       "      <td>{'000': 0.016373653066597823, '95': 0.01637365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                          Averting the climate crisis   \n",
       "1                      The best stats you've ever seen   \n",
       "2                                     Simplicity sells   \n",
       "3                                  Greening the ghetto   \n",
       "4                          Do schools kill creativity?   \n",
       "...                                                ...   \n",
       "4000       Crisis support for the world, one text away   \n",
       "4001                      The dark history of IQ tests   \n",
       "4002  How \"policing for profit\" undermines your rights   \n",
       "4003      The electrifying speeches of Sojourner Truth   \n",
       "4004              The most important anus in the ocean   \n",
       "\n",
       "                                        occupations native_lang  \\\n",
       "0                         {0: ['climate advocate']}          en   \n",
       "1     {0: ['global health expert; data visionary']}          en   \n",
       "2                     {0: ['technology columnist']}          en   \n",
       "3       {0: ['activist for environmental justice']}          en   \n",
       "4                       {0: ['author', 'educator']}          en   \n",
       "...                                             ...         ...   \n",
       "4000                       {0: ['health activist']}          en   \n",
       "4001                                            NaN          en   \n",
       "4002                        {0: ['law researcher']}          en   \n",
       "4003                                            NaN          en   \n",
       "4004                                            NaN          en   \n",
       "\n",
       "                                                 topics  \\\n",
       "0     [alternative energy, cars, climate change, cul...   \n",
       "1     [africa, asia, google, demo, economics, global...   \n",
       "2     [computers, entertainment, interface design, m...   \n",
       "3     [macarthur grant, activism, business, cities, ...   \n",
       "4     [children, creativity, culture, dance, educati...   \n",
       "...                                                 ...   \n",
       "4000  [activism, data, technology, mental health, so...   \n",
       "4001  [ted-ed, education, history, animation, intell...   \n",
       "4002       [society, law, policy, justice system, tedx]   \n",
       "4003  [ted-ed, education, animation, united states, ...   \n",
       "4004  [animals, ted-ed, animation, oceans, science, ...   \n",
       "\n",
       "                                          related_talks  \\\n",
       "0     {243: 'New thinking on the climate crisis', 54...   \n",
       "1     {2056: \"Own your body's data\", 2296: 'A visual...   \n",
       "2     {1725: '10 top time-saving tech tips', 2274: '...   \n",
       "3     {1041: '3 stories of local eco-entrepreneurshi...   \n",
       "4     {865: 'Bring on the learning revolution!', 173...   \n",
       "...                                                 ...   \n",
       "4000  {2362: 'How data from a crisis text line is sa...   \n",
       "4001  {35386: 'How does the Rorschach inkblot test w...   \n",
       "4002  {2406: 'I love being a police officer, but we ...   \n",
       "4003  {20973: 'The breathtaking courage of Harriet T...   \n",
       "4004  {62347: 'The bug that poops candy', 29159: 'In...   \n",
       "\n",
       "                                            description  \\\n",
       "0     With the same humor and humanity he exuded in ...   \n",
       "1     You've never seen data presented like this. Wi...   \n",
       "2     New York Times columnist David Pogue takes aim...   \n",
       "3     In an emotionally charged talk, MacArthur-winn...   \n",
       "4     Sir Ken Robinson makes an entertaining and pro...   \n",
       "...                                                 ...   \n",
       "4000  What if we could help people in crisis anytime...   \n",
       "4001  In 1905, psychologists Alfred Binet and Théodo...   \n",
       "4002  Many countries have an active, centuries-old l...   \n",
       "4003  Isabella Baumfree was born into slavery in lat...   \n",
       "4004  Is it a fuzzy sock? An overripe banana? A mold...   \n",
       "\n",
       "                                             transcript  \\\n",
       "0     Thank you so much, Chris. And it's truly a gre...   \n",
       "1     About 10 years ago, I took on the task to teac...   \n",
       "2     (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3     If you're here today — and I'm very happy that...   \n",
       "4     Good morning. How are you? (Audience) Good. It...   \n",
       "...                                                 ...   \n",
       "4000  \"I'm 14, and I want to go home.\" \"My name is B...   \n",
       "4001  In 1905, psychologists Alfred Binet and Théodo...   \n",
       "4002  Picture yourself driving down the road tomorro...   \n",
       "4003  In early 1828, Sojourner Truth approached the ...   \n",
       "4004  Can you guess what you’re looking at? Is it a ...   \n",
       "\n",
       "                     grouped_topics  \\\n",
       "0                   {culture, stem}   \n",
       "1                  {business, stem}   \n",
       "2                            {stem}   \n",
       "3     {business, activism, history}   \n",
       "4                         {culture}   \n",
       "...                             ...   \n",
       "4000      {culture, activism, stem}   \n",
       "4001                {stem, history}   \n",
       "4002                      {culture}   \n",
       "4003            {activism, history}   \n",
       "4004                         {stem}   \n",
       "\n",
       "                                          clean_scripts  \\\n",
       "0     thank you so much chris and its truly a great ...   \n",
       "1     about 10 years ago i took on the task to teach...   \n",
       "2     hello voice mail my old friend (laughter) ive ...   \n",
       "3     if youre here today and im very happy that you...   \n",
       "4     good morning how are you (audience) good its b...   \n",
       "...                                                 ...   \n",
       "4000  im 14 and i want to go home my name is beth im...   \n",
       "4001  in 1905 psychologists alfred binet and théodor...   \n",
       "4002  picture yourself driving down the road tomorro...   \n",
       "4003  in early 1828 sojourner truth approached the g...   \n",
       "4004  can you guess what you’re looking at is it a f...   \n",
       "\n",
       "                                                  words  \\\n",
       "0     {'thank': 3, 'you': 39, 'so': 5, 'much': 9, 'c...   \n",
       "1     {'about': 15, '10': 3, 'years': 9, 'ago': 1, '...   \n",
       "2     {'hello': 1, 'voice': 3, 'mail': 2, 'my': 17, ...   \n",
       "3     {'if': 6, 'youre': 3, 'here': 6, 'today': 3, '...   \n",
       "4     {'good': 4, 'morning': 1, 'how': 7, 'are': 19,...   \n",
       "...                                                 ...   \n",
       "4000  {'im': 3, '14': 1, 'and': 76, 'i': 14, 'want':...   \n",
       "4001  {'in': 17, '1905': 1, 'psychologists': 3, 'alf...   \n",
       "4002  {'picture': 1, 'yourself': 1, 'driving': 1, 'd...   \n",
       "4003  {'in': 20, 'early': 1, '1828': 2, 'sojourner':...   \n",
       "4004  {'can': 5, 'you': 1, 'guess': 1, 'what': 2, 'y...   \n",
       "\n",
       "                                                one-hot  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, ...   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "...                                                 ...   \n",
       "4000  [1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "4001  [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "4002  [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "4003  [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "4004  [0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "\n",
       "                                          sentence-type  \\\n",
       "0     [0.9096774193548387, 0.05806451612903226, 0.04...   \n",
       "1     [0.9116465863453815, 0.09236947791164658, 0.00...   \n",
       "2     [0.8561872909698997, 0.12040133779264214, 0.03...   \n",
       "3     [0.9187817258883249, 0.06598984771573604, 0.02...   \n",
       "4     [0.8489208633093526, 0.14388489208633093, 0.01...   \n",
       "...                                                 ...   \n",
       "4000  [0.9632352941176471, 0.04411764705882353, 0.00...   \n",
       "4001    [1.0, 0.02857142857142857, 0.02857142857142857]   \n",
       "4002  [0.944954128440367, 0.06422018348623854, 0.009...   \n",
       "4003                               [0.95, 0.025, 0.075]   \n",
       "4004  [0.8888888888888888, 0.1388888888888889, 0.027...   \n",
       "\n",
       "                                                  tfidf  \\\n",
       "0     [0.004944137818219958, 0.004944137818219958, 0...   \n",
       "1     [0.0029276458487846966, 0.00878293754635409, 0...   \n",
       "2     [0.003229757844257144, 0.003229757844257144, 0...   \n",
       "3     [0.015522192347839546, 0.007761096173919773, 0...   \n",
       "4     [0.0033326113457486047, 0.0066652226914972095,...   \n",
       "...                                                 ...   \n",
       "4000  [0.017823075144987977, 0.005941025048329325, 0...   \n",
       "4001  [0.03855034965325704, 0.01285011655108568, 0.0...   \n",
       "4002  [0.02596745720022887, 0.006491864300057218, 0....   \n",
       "4003  [0.01362089413207989, 0.01362089413207989, 0.0...   \n",
       "4004  [0.016373653066597823, 0.016373653066597823, 0...   \n",
       "\n",
       "                                             tfidf_word  \\\n",
       "0     [238, 28, 30, 31, 39, 40, 50, about, accomplis...   \n",
       "1     [000, 10, 100, 1960, 1962, 1964, 1970, 1974, 2...   \n",
       "2     [000, 10, 11, 12, 18, 1982, 1997, 20, 200, 200...   \n",
       "3     [000, 10, 1960s, 1990s, 1998, 20, 25, 27, 28, ...   \n",
       "4     [15, 16, 1930s, 19th, 20, 2065, 21, 30, 30s, 5...   \n",
       "...                                                 ...   \n",
       "4000  [000, 12, 14, 150, 17, 19, 20, 2013, 24, 26, 2...   \n",
       "4001  [100, 15, 1905, 1924, 19th, 20th, 68, abilitie...   \n",
       "4002  [000, 1955, 1980s, 1990, 1997, 200, 2001, 2002...   \n",
       "4003  [1799, 1826, 1828, 1843, 1883, 18th, 20s, 80s,...   \n",
       "4004  [000, 95, able, about, abyssal, acidification,...   \n",
       "\n",
       "                                             tfidf_dict  \n",
       "0     {'238': 0.004944137818219958, '28': 0.00494413...  \n",
       "1     {'000': 0.0029276458487846966, '10': 0.0087829...  \n",
       "2     {'000': 0.003229757844257144, '10': 0.00322975...  \n",
       "3     {'000': 0.015522192347839546, '10': 0.00776109...  \n",
       "4     {'15': 0.0033326113457486047, '16': 0.00666522...  \n",
       "...                                                 ...  \n",
       "4000  {'000': 0.017823075144987977, '12': 0.00594102...  \n",
       "4001  {'100': 0.03855034965325704, '15': 0.012850116...  \n",
       "4002  {'000': 0.02596745720022887, '1955': 0.0064918...  \n",
       "4003  {'1799': 0.01362089413207989, '1826': 0.013620...  \n",
       "4004  {'000': 0.016373653066597823, '95': 0.01637365...  \n",
       "\n",
       "[4005 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2e4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8bd55ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd8e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84848de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
